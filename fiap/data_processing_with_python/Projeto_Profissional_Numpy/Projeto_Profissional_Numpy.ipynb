{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e0db970",
   "metadata": {},
   "source": [
    "#### Projeto Profissional Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb33b29",
   "metadata": {},
   "source": [
    "#### Vamos trabalhar com um projeto prático utilizando um dataset público, onde iremos explorar, manipular e transformar este dataset e deixar os dados prontos para aplicar análises, uma tarefa muito comum no dia a dia trabalhando com dados, vamos fazer tudo isso utilizando apenas o NumPy.\n",
    "\n",
    "#### O dataset será disponibilizado e foi extraído no link abaixo:\n",
    "\n",
    "#### https://www.openintro.org/data/index.php?data=loans_full_schema\n",
    "\n",
    "#### É um dataset público disponibilizado por uma plataforma Lending  Club que permitem que individuos emprestem dinheiro para outros individuos, a disponibilidade do empréstimo e o valor de juros variam de acordo com o perfil do individuo, porém não é um dataset com pedidos de empréstimos, mas sim históricos de empréstimos feitos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9370a8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos começar e importar o pacote numpy\n",
    "# Caso voce não consiga importa-lo tente usar o comando !pip install numpy e depois faça a importacao\n",
    "import numpy as np\n",
    "\n",
    "# Veja que importamos o numpy com o \"apelido\" de np que sempre será utilizado quando formos chamar as funcoes do numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07116e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.26.4\n"
     ]
    }
   ],
   "source": [
    "# Vamos verificar a versao utilizada neste curso do numpy, e importante que voce utilize a mesma versao\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2fd159",
   "metadata": {},
   "source": [
    "#### manual de funcionamento oficial do criador do NumPy "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc8d2b4",
   "metadata": {},
   "source": [
    "https://numpy.org/doc/stable/reference/generated/numpy.set_printoptions.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "693288c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurando as saidas do NumPy com set_printoptions\n",
    "# Vamos usar uma funcao set_printoptions, ela determina opcoes para vc tratar numeros e objetos numpy\n",
    "# Ela possui uma serie de parametros\n",
    "# Vamos colocar o precision = 4 pq queremos 4 numeros depois da virgula\n",
    "# Com essa funcao vc consegue formatar as saidas que vc tem com numpy padronizando seu trabalho\n",
    "\n",
    "np.set_printoptions(suppress = True, linewidth = 200, precision = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52bc6100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos tambem remover as mensagens de warning que sao varias para nao deixar o projeto poluido\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13ec00d",
   "metadata": {},
   "source": [
    "### Carga dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc4a3e3",
   "metadata": {},
   "source": [
    "https://numpy.org/doc/stable/reference/generated/numpy.genfromtxt.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fbe30be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos carregar o data set usando a funcao genfromtxt\n",
    "# Esta funcao carrega um arquivo do disco, no nosso caso um csv\n",
    "# E carrega na memoria, tbm tem varios parametros\n",
    "\n",
    "# datasets/dataset_sujo.csv - Vamos indicar o dataset_sujo que temos no diretorio de dados datasets\n",
    "# delimiter = ';' - Passamos o delimitador, ou seja o sinal usado para separar as colunas\n",
    "# skip_header = 1 - Vamos ignorar o cabecalho, nao vamos carregar ele neste inicio\n",
    "# autostrip = True - Vamos remover espacos dentro de cada coluna que tiver na direita ou esquerda do registro\n",
    "# encoding = 'cp1252'- Por ultimo vamos definir encoding que e como vou ser lidos os dados\n",
    "# Caso vc tiver problema com o encoding entre na documentacao e veja outro encoding que possa estar correto\n",
    "# Outro encoding muito utilizado aqui no brasil é o utf-8 vc vai se deparar ou ja se deparou muito com ele\n",
    "\n",
    "dados1 = np.genfromtxt(\"dataset_sujo.csv\", \n",
    "                       delimiter = ';', \n",
    "                       skip_header = 1, \n",
    "                       autostrip = True, \n",
    "                       encoding = 'cp1252')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff5e7add",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vamos ver o tipo de objeto criado \n",
    "# Veja que e um ndarray\n",
    "# Ou seja um array de varias dimensoes\n",
    "type(dados1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f745d515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 14)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vamos verificar o shape\n",
    "# Temos 10000 linhas para 14 colunas\n",
    "dados1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0307cf55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[48010226.  ,         nan,    35000.  , ...,         nan,         nan,     9452.96],\n",
       "       [57693261.  ,         nan,    30000.  , ...,         nan,         nan,     4679.7 ],\n",
       "       [59432726.  ,         nan,    15000.  , ...,         nan,         nan,     1969.83],\n",
       "       ...,\n",
       "       [50415990.  ,         nan,    10000.  , ...,         nan,         nan,     2185.64],\n",
       "       [46154151.  ,         nan,         nan, ...,         nan,         nan,     3199.4 ],\n",
       "       [66055249.  ,         nan,    10000.  , ...,         nan,         nan,      301.9 ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vamos ver uma amostra dos dados\n",
    "# Perceba que ja temos um problema no dataset\n",
    "# Temos varios valores nan = valores nullos\n",
    "\n",
    "# Porem na verdade se vc verificar o arquivo, os valores nao estao ausentes\n",
    "# Na verdade ele nao conseguiu ler os caracteres especiais\n",
    "# No momento que carregamos os dados o numpy noa reconheceu as colunas com esses caracteres\n",
    "# O problema nao esta nos dados mas sim em como  numpy carregou o dataset\n",
    "# Nosso primeiro desafio vai ser corrigir o carregamento dos dados\n",
    "\n",
    "dados1.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0675f70d",
   "metadata": {},
   "source": [
    "### Resolvendo problema de carga nos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a38589a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88005"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# usar uma saida provisoria ja que usamos apenas o numpy para este projeto\n",
    "# gerou problemas com as colunas strings\n",
    "\n",
    "# ver quantos valores ausentes foram gerados\n",
    "# A funcao isnan vai verificar cada um dos valores do dataset\n",
    "# isnan vai retornar true ou false para cada valor nan\n",
    "# usar o sum() para somar a quantidade de True\n",
    "# o dataset tem valores ausentes\n",
    "# Porem grande parte deles foram gerados pelo numpy na hora de carregar os dados\n",
    "\n",
    "\n",
    "np.isnan(dados1).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19452aec",
   "metadata": {},
   "source": [
    "https://numpy.org/doc/stable/reference/generated/numpy.nanmax.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96407a36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68616522.0\n"
     ]
    }
   ],
   "source": [
    "# precisamos das variaveis string e das variaveis numericas\n",
    "# carregar estas variaveis separadamente a principio para trata-las\n",
    "# criar 2 datasets separado pelo tipo de variavel\n",
    "# Um dataset numerico e um com strings\n",
    "\n",
    "# retornar o maior valor + 3 sem considerar valores NAN\n",
    "# Poderiamos usar qualquer valor, \n",
    "# porem usando o nanmax nos criamos um valor personalizado de acordo com o dataset\n",
    "# Usaremos esse valor para identificar os valores nan do dataset na hora de carregar variaveis numericas\n",
    "# Depois vamos tratar esse valor_nan como valor ausente\n",
    "# Estamos apenas mudando o valor NAN para um valor numerico que significa para nós ser o NAN\n",
    "# E uma especie de encoding numerico de valor ausente\n",
    "\n",
    "valores_nan = np.nanmax(dados1) + 3\n",
    "print(valores_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d74319cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exemplo\n",
    "a = np.array([[1, 2], [3, np.nan]])\n",
    "np.nanmax(a)\n",
    "#3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5962db2f",
   "metadata": {},
   "source": [
    "https://numpy.org/doc/stable/reference/generated/numpy.nanmean.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b1c8ca43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[54015809.1922           nan    15273.4632           nan    15311.0421           nan       16.6173      440.9222           nan           nan           nan           nan           nan     3143.8509]\n"
     ]
    }
   ],
   "source": [
    "# O próximo passo vai nos ajudar a separar as colunas strings e numéricas\n",
    "\n",
    "# calculando a média dos valores onde não estiver como NAN\n",
    "# Usaremos isso para separar variáveis numéricas de variáveis do tipo string\n",
    "\n",
    "# Vamos aplicar ela em nivel de coluna (axis=0)\n",
    "\n",
    "# Ele vai ignorar os valores NAN das colunas e aplicar a média\n",
    "\n",
    "# Veja que ele trouxe a média por coluna\n",
    "# Veja que as colunas NAN ele trouxe como NAN\n",
    "\n",
    "media_sem_nan = np.nanmean(dados1, axis = 0) # nivel coluna(axis=0)\n",
    "print(media_sem_nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872f5a9e",
   "metadata": {},
   "source": [
    "https://numpy.org/doc/stable/reference/generated/numpy.argwhere.html\n",
    "\n",
    "https://numpy.org/doc/stable/reference/generated/numpy.squeeze.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f7e77bda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  3,  5,  8,  9, 10, 11, 12])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Busca Colunas do tipo STRING com valores ausentes\n",
    "\n",
    "# argwhere encontra os indices dos elementos do array que são diferentes de zero agrupado por elementos\n",
    "# onde vamos peguntar isnan dentro do media_sem_nan\n",
    "# Se for NAN (ou seja NAN que o numpy nao conseguiu carregar)\n",
    "\n",
    "# A função SQUEEZE coloca tudo em um array / lista numpy\n",
    "cols_str = np.argwhere(np.isnan(media_sem_nan)).squeeze() \n",
    "cols_str\n",
    "\n",
    "# Veja nós sabemos onde estão as colunas strings pois o numpy as leu como NAN\n",
    "# Então usamos isso para identificá-las e conseguir separá-las"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "53cc6354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  2,  4,  6,  7, 13])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Colunas numéricas \n",
    "\n",
    "# Vamos fazer a mesma busca agora porém agora queremos == false\n",
    "# REtorna apenas as colunas numéricas\n",
    "# E vamos gerar a lista com squeeze \n",
    "# Contendo os índices das colunas do tipo numérica com argwhere\n",
    "# E fazendo a verificação dessas colunas com np.isnan(media_sem_nan) == False\n",
    "cols_num = np.argwhere(np.isnan(media_sem_nan) == False).squeeze()\n",
    "cols_num"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e718a8",
   "metadata": {},
   "source": [
    "#### Vamos importar novamente os datasets, dessa vez separando as colunas do tipo string de colunas numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3cc4648f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando as colunas do tipo string\n",
    "# Agora vamos carregar porém usando novos argumentos com base no que criamos anteriormente\n",
    "# Vamos carregar as colunas e passar a lista de indices (cols_str) das colunas do tipo texto\n",
    "# E ainda falamos para o numpy que essas colunas são do tipo string \"dtype = str\"\n",
    "dados_str = np.genfromtxt(\"dataset_sujo.csv\",\n",
    "                            delimiter = ';',\n",
    "                            skip_header = 1,\n",
    "                            autostrip = True, \n",
    "                            usecols = cols_str,\n",
    "                            dtype = str, \n",
    "                            encoding = 'cp1252')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "79576d1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['May-15', 'Current', '36 months', ..., 'Verified', 'https://www.lendingclub.com/browse/loanDetail.action?loan_id=48010226', 'CA'],\n",
       "       ['', 'Current', '36 months', ..., 'Source Verified', 'https://www.lendingclub.com/browse/loanDetail.action?loan_id=57693261', 'NY'],\n",
       "       ['Sep-15', 'Current', '36 months', ..., 'Verified', 'https://www.lendingclub.com/browse/loanDetail.action?loan_id=59432726', 'PA'],\n",
       "       ...,\n",
       "       ['Jun-15', 'Current', '36 months', ..., 'Source Verified', 'https://www.lendingclub.com/browse/loanDetail.action?loan_id=50415990', 'CA'],\n",
       "       ['Apr-15', 'Current', '36 months', ..., 'Source Verified', 'https://www.lendingclub.com/browse/loanDetail.action?loan_id=46154151', 'OH'],\n",
       "       ['Dec-15', 'Current', '36 months', ..., '', 'https://www.lendingclub.com/browse/loanDetail.action?loan_id=66055249', 'IL']], dtype='<U69')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veja que agora os dados foram carregados\n",
    "dados_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8e6a7a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando as colunas do tipo numérico preenchendo os valores ausentes\n",
    "# Porém preenchendo os valores vazios com o encoding que criamos para valores NAN (valores_nan)\n",
    "dados_num = np.genfromtxt(\"dataset_sujo.csv\",\n",
    "                            delimiter = ';',\n",
    "                            autostrip = True,\n",
    "                            skip_header = 1,\n",
    "                            usecols = cols_num,\n",
    "                            filling_values = valores_nan, \n",
    "                            encoding = 'cp1252')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "72e19e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[48010226.  ,    35000.  ,    35000.  ,       13.33,     1184.86,     9452.96],\n",
       "       [57693261.  ,    30000.  ,    30000.  , 68616522.  ,      938.57,     4679.7 ],\n",
       "       [59432726.  ,    15000.  ,    15000.  , 68616522.  ,      494.86,     1969.83],\n",
       "       ...,\n",
       "       [50415990.  ,    10000.  ,    10000.  , 68616522.  , 68616522.  ,     2185.64],\n",
       "       [46154151.  , 68616522.  ,    10000.  ,       16.55,      354.3 ,     3199.4 ],\n",
       "       [66055249.  ,    10000.  ,    10000.  , 68616522.  ,      309.97,      301.9 ]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veja que os valores NAN foram substituídos pelo valor identificador que criamos para NAN\n",
    "# 68616522.0 - este valor não existe no dataset pois ele é o valor MAX+3\n",
    "# Assim conseguimos codificar os valores NAN sem ter o risco de criar um valor já existente nos dados\n",
    "dados_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e99d6aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora vamos extrair os nomes das colunas\n",
    "# Vamos pegar o indice de linha [0] onde estao os nomes (dados1.shape[0])\n",
    "# se fosse carregado antes, daria problema no numpy pois haveria texto nas colunas numericas\n",
    "nomes_cols = np.genfromtxt(\"dataset_sujo.csv\",\n",
    "                                  delimiter = ';',\n",
    "                                  autostrip = True,\n",
    "                                  skip_footer = dados1.shape[0],\n",
    "                                  dtype = str, \n",
    "                                  encoding = 'cp1252')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3ec47b6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'issue_d', 'loan_amnt', 'loan_status', 'funded_amnt', 'term', 'int_rate', 'installment', 'grade', 'sub_grade', 'verification_status', 'url', 'addr_state', 'total_pymnt'], dtype='<U19')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nomes_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4252e476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos separar os nomes das colunas strings e numéricas para usar depois\n",
    "nomes_colunas_str, nomes_colunas_num = nomes_cols[cols_str], nomes_cols[cols_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "57ce5866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_d', 'loan_status', 'term', 'grade', 'sub_grade', 'verification_status', 'url', 'addr_state'], dtype='<U19')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nomes_colunas_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8cc51623",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'loan_amnt', 'funded_amnt', 'int_rate', 'installment', 'total_pymnt'], dtype='<U19')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nomes_colunas_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d55561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# usamos a estratégia de criar um valor identificador de NAN\n",
    "# Identificamos as colunas numéricas dos textos que estavam como NAN\n",
    "# Então carregamos os dados separados por tipo de dado\n",
    "# E no final pegamos os nomes das colunas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fb9d04",
   "metadata": {},
   "source": [
    "#### Salvando resultado intermediario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c6a986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Este dataset é relativamente pequeno, ou seja, não precisaria do checkpoint\n",
    "# Porem será normal termos um grande volume de dados para trabalhar\n",
    "# Principalmente se estiver usando o numpy\n",
    "\n",
    "# Esta função permite salvar o resultado das suas transformações, assim no dia a dia vc perde muito menos tempo\n",
    "# Pois basta fazer as transformações e então gerar um checkpoint para não precisar refazê-las e perder tempo\n",
    "# Pois dependendo do volume de dados isso pode demorar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "392ca174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint\n",
    "# Ela vai salvar em disco tudo que fizemos até aqui\n",
    "# Vamos salvar os dois datasets de strings pois é o mais trabalhoso\n",
    "\n",
    "# Vamos criar uma função que recebe 3 argumentos:\n",
    "    # nome do diretorio do arquivo de saida, \n",
    "    # cabecalho das colunas\n",
    "    # e os dados que queremos salvar\n",
    "\n",
    "def checkpoint(diretorio, cabecalho, dados):\n",
    "    np.savez(diretorio, header = cabecalho, data = dados)\n",
    "    checkpoint_var = np.load(diretorio + \".npz\")\n",
    "    return(checkpoint_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8f102936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos executar a função\n",
    "# Veja que em seu diretório estará o novo arquivo\n",
    "checkpoint_str = checkpoint(\"Checkpoint_str\", nomes_cols, dados_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9421cc2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['May-15', 'Current', '36 months', ..., 'Verified', 'https://www.lendingclub.com/browse/loanDetail.action?loan_id=48010226', 'CA'],\n",
       "       ['', 'Current', '36 months', ..., 'Source Verified', 'https://www.lendingclub.com/browse/loanDetail.action?loan_id=57693261', 'NY'],\n",
       "       ['Sep-15', 'Current', '36 months', ..., 'Verified', 'https://www.lendingclub.com/browse/loanDetail.action?loan_id=59432726', 'PA'],\n",
       "       ...,\n",
       "       ['Jun-15', 'Current', '36 months', ..., 'Source Verified', 'https://www.lendingclub.com/browse/loanDetail.action?loan_id=50415990', 'CA'],\n",
       "       ['Apr-15', 'Current', '36 months', ..., 'Source Verified', 'https://www.lendingclub.com/browse/loanDetail.action?loan_id=46154151', 'OH'],\n",
       "       ['Dec-15', 'Current', '36 months', ..., '', 'https://www.lendingclub.com/browse/loanDetail.action?loan_id=66055249', 'IL']], dtype='<U69')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_str['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "791b9747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apenas para verificação vamos usar a função array_equal\n",
    "# Para ver se os dados que salvamos são realmente iguais os dados que criamos\n",
    "# No caso simplesmente as colunas strings ajustadas\n",
    "# Claro veja que são iguais mesmo ou seja armazenamos corretamente\n",
    "np.array_equal(checkpoint_str['data'], dados_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544e850b",
   "metadata": {},
   "source": [
    "### Trabalhando com as Colunas do Tipo Texto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673c69f6",
   "metadata": {},
   "source": [
    "##### Se fossemos criar depois um modelo de machine learning não poderia haver texto, pois machine learning é pura matematica! Devido isso, precisamos passar os textos para sua representação numérica sem perder a informação no final as colunas texto serao transformadas em números. Em autoML essa transformação é contida dentro do algorítmo em alguns modelos, porém fazemos com Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cd8f9906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_d', 'loan_status', 'term', 'grade', 'sub_grade', 'verification_status', 'url', 'addr_state'], dtype='<U19')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vamos ver os nomes das colunas do tipo texto\n",
    "\n",
    "nomes_colunas_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "21f110b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos mudar o nome da coluna issue_d para issue_date para identificar melhor a coluna\n",
    "nomes_colunas_str[0] = \"issue_date\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9ac09ae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_date', 'loan_status', 'term', 'grade', 'sub_grade', 'verification_status', 'url', 'addr_state'], dtype='<U19')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nomes_colunas_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d35ed73f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['May-15', 'Current', '36 months', ..., 'Verified', 'https://www.lendingclub.com/browse/loanDetail.action?loan_id=48010226', 'CA'],\n",
       "       ['', 'Current', '36 months', ..., 'Source Verified', 'https://www.lendingclub.com/browse/loanDetail.action?loan_id=57693261', 'NY'],\n",
       "       ['Sep-15', 'Current', '36 months', ..., 'Verified', 'https://www.lendingclub.com/browse/loanDetail.action?loan_id=59432726', 'PA'],\n",
       "       ...,\n",
       "       ['Jun-15', 'Current', '36 months', ..., 'Source Verified', 'https://www.lendingclub.com/browse/loanDetail.action?loan_id=50415990', 'CA'],\n",
       "       ['Apr-15', 'Current', '36 months', ..., 'Source Verified', 'https://www.lendingclub.com/browse/loanDetail.action?loan_id=46154151', 'OH'],\n",
       "       ['Dec-15', 'Current', '36 months', ..., '', 'https://www.lendingclub.com/browse/loanDetail.action?loan_id=66055249', 'IL']], dtype='<U69')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43315c43",
   "metadata": {},
   "source": [
    "### Transformando a Variável <b>issue_date</b> com Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4db46463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', 'Apr-15', 'Aug-15', 'Dec-15', 'Feb-15', 'Jan-15', 'Jul-15', 'Jun-15', 'Mar-15', 'May-15', 'Nov-15', 'Oct-15', 'Sep-15'], dtype='<U69')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Começando pela primeira variável texto do dados_str: a issue_date \n",
    "# Vamos ver os valores únicos desta variável / coluna com a função unique usando o slicing \n",
    "\n",
    "np.unique(dados_str[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6d4bc4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veja que temos os meses dos ano porém os dados vieram com um \"-15\" junto dos meses\n",
    "# Isso é o padrão de nome que o sistema gerou, sendo muito comum no dia a dia\n",
    "# Sistemas tem padrões muitas vezes diferente do qual vc quer trabalhar\n",
    "\n",
    "# Vamos remover o sufixo \"-15\" e converter em um array de strings usando a função STRIP()\n",
    "\n",
    "# No caso do dataset dados_str da coluna de indice 0\n",
    "# Onde for  \"-15\"\n",
    "# Vamos converter a variavel para o tipo chararray\n",
    "dados_str[:,0] = np.chararray.strip(dados_str[:,0], \"-15\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "97df06f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', 'Apr', 'Aug', 'Dec', 'Feb', 'Jan', 'Jul', 'Jun', 'Mar', 'May', 'Nov', 'Oct', 'Sep'], dtype='<U69')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veja que os registros desta coluna foram padronizados\n",
    "# Veja que temos valores ausentes ainda nesta coluna\n",
    "np.unique(dados_str[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4e3308a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos criar um array com os meses, considerando o vazio, precisamos considerá-lo por enquanto\n",
    "meses = np.array(['', 'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fa4dc725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precisamos converter os textos para sua representacao numérica\n",
    "# Então criamos um Loop para converter os nomes dos meses em valores numéricos\n",
    "# Chamamos isso de LABEL ENCODING\n",
    "\n",
    "# Para cada elemento de dados_str[:,0]\n",
    "# Vamos checar se bate com o array de meses criado acima\n",
    "# Se bater nós vamos alimentar com i; se não bater vamos manter o valor que já existe\n",
    "# É para funcionar pois consideramos todos os valores dessa coluna na hora de criar o meses \n",
    "for i in range(13):\n",
    "        dados_str[:,0] = np.where(dados_str[:,0] == meses[i], i, dados_str[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4945b73f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '1', '10', '11', '12', '2', '3', '4', '5', '6', '7', '8', '9'], dtype='<U69')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A forma que criamos o array meses e criamos o loop\n",
    "# fez com que cada mes recebesse o seu número correspondente na ordem de meses dos anos\n",
    "# Ou seja, vazio recebeu 0, janeiro-1, fevereiro-2, etc\n",
    "# Isso foi por causa do jeito que criamos o array meses e verificamos com o loop\n",
    "# uma forma fácil de mudar os nomes sem precisar usar funções if etc\n",
    "\n",
    "np.unique(dados_str[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e875a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding é o processo de converter variáveis categóricas de uma variável para sua versão numérica\n",
    "# Isso sem perder a informação da variável, claro!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a902fd8b",
   "metadata": {},
   "source": [
    "### Transformando a variável <b>loan_status</b> com Binarização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "527c0390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_date', 'loan_status', 'term', 'grade', 'sub_grade', 'verification_status', 'url', 'addr_state'], dtype='<U19')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vamos agora transformar a segunda variável, desta vez vamos usar binarização\n",
    "nomes_colunas_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0e845dee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', 'Charged Off', 'Current', 'Default', 'Fully Paid', 'In Grace Period', 'Issued', 'Late (16-30 days)', 'Late (31-120 days)'], dtype='<U69')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando os valores únicos com unique\n",
    "# Da coluna / variável de indice 1\n",
    "np.unique(dados_str[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c87f9f7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Número de categorias dessa variável\n",
    "# Analisando o caso, podemos chegar a conclusão que para a análise que estamos fazendo\n",
    "# não precisamos das nove categorias pois elas podem se dividir em 2 principais grupos:\n",
    "    # as categorias ruins e as boas, aquilo que foi pago e aquilo que não foi pago basicamente\n",
    "\n",
    "# Entaão vamos aplicar a binarização para este problema\n",
    "# Binarizacao é vc binarizar uma variavel em 0 e 1\n",
    "\n",
    "np.unique(dados_str[:,1]).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cbbfe43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criamos um array identificando os status que consideramos ruim\n",
    "# Parecido com o que fizemos com os meses\n",
    "\n",
    "status_ruins = np.array(['', 'Charged Off', 'Default', 'Late (31-120 days)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "10a542d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checamos agora os valores da variavel com where\n",
    "# e comparamos com o array que criamos convertendo as variáveis para valores binários\n",
    "\n",
    "# Vamos usar a funcao \"isin\"\n",
    "# Ela vai verificar se dentro do dados_str[:,1] tem status_ruins\n",
    "# Se tiver eu coloco 0, senão coloco 1\n",
    "# 0 a classe ruim e 1 a classe boa\n",
    "\n",
    "dados_str[:,1] = np.where(np.isin(dados_str[:,1], status_ruins),0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "df0f87d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '1'], dtype='<U69')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Agora vemos que essa coluna foi binarizada\n",
    "# Essa transformação é muito usada na área de dados\n",
    "# A binarização é uma das melhores técnicas para vc analisar dados\n",
    "# Ela tem muitas aplicações sempre tenha ela em seu repertório\n",
    "\n",
    "np.unique(dados_str[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d81bb1",
   "metadata": {},
   "source": [
    "### Transformando a Variavel <b>term</b> com limpeza de string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ea255d8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_date', 'loan_status', 'term', 'grade', 'sub_grade', 'verification_status', 'url', 'addr_state'], dtype='<U19')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nomes_colunas_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "dacb1812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', '36 months', '60 months'], dtype='<U69')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Valores da coluna term\n",
    "# Veja que o processo vai se repetindo\n",
    "# Perceba que esta variável é numérica\n",
    "# Porém ela tem palavras junto o que atrapalha a análise\n",
    "# Precisamos limpar esta variável / coluna\n",
    "np.unique(dados_str[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8d178801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['36', '36', '36', ..., '36', '36', '36'], dtype='<U69')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removemos a palavra months (observe o espaço antes da palavra)\n",
    "# Vamos usar novamente a função STRIP() para remover a palavra months\n",
    "# Perceba que incluímos o \" \" espaco na remoção\n",
    "# Pois ele impede de convertermos a variável para numérica\n",
    "dados_str[:,2] = np.chararray.strip(dados_str[:,2], \" months\")\n",
    "dados_str[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "81eb46f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'term_months'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Agora vamos melhorar o nome da coluna\n",
    "# Indicando que é uma coluna de term months para ajudar na identificação\n",
    "nomes_colunas_str[2] = \"term_months\"\n",
    "nomes_colunas_str[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "327a75bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# E também tomamos a decisão de preencher o valor vazio com 60 que é o maior prazo\n",
    "# Vamos supor que esta foi uma decisao combinada com a equipe de negócios ou por vc mesmo baseado na sua análise\n",
    "# Com np.where vamos mudar o que for vazio para 60\n",
    "dados_str[:,2] = np.where(dados_str[:,2] == '', '60', dados_str[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "95c277dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['36', '36', '36', ..., '36', '36', '36'], dtype='<U69')"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veja que agora nao temos valores vazios\n",
    "dados_str[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "68ca9e57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['36', '60'], dtype='<U69')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando os valores únicos para confirmar\n",
    "np.unique(dados_str[:,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c1a9e8",
   "metadata": {},
   "source": [
    "### Transformando a variável <b>grade</b> e <b>sub_grade</b> com dicionario (um tipo de Label Encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "971c556b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_date', 'loan_status', 'term_months', 'grade', 'sub_grade', 'verification_status', 'url', 'addr_state'], dtype='<U19')"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"grade\" e uma espécie de nota que o cliente que pede empréstimo recebe\n",
    "# \"sub grade\" é uma variável parecida com a grade\n",
    "nomes_colunas_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ff34e67b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', 'A', 'B', 'C', 'D', 'E', 'F', 'G'], dtype='<U69')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando os valores únicos\n",
    "np.unique(dados_str[:,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c6c9c1bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', 'A1', 'A2', 'A3', 'A4', 'A5', 'B1', 'B2', 'B3', 'B4', 'B5', 'C1', 'C2', 'C3', 'C4', 'C5', 'D1', 'D2', 'D3', 'D4', 'D5', 'E1', 'E2', 'E3', 'E4', 'E5', 'F1', 'F2', 'F3', 'F4', 'F5', 'G1',\n",
       "       'G2', 'G3', 'G4', 'G5'], dtype='<U69')"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando os valores únicos\n",
    "np.unique(dados_str[:,4])\n",
    "\n",
    "# Perceba que as variaveis tem informacoes parecidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe80d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Em algumas análises, nós temos que remover variáveis que representam a mesma informacao\n",
    "# Isso prejudica o modelo de machine learning \n",
    "# Por isso iremos remover uma das variáveis\n",
    "# No caso iremos manter a variável \"sub grade\" pois ela e mais detalhada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47707f29",
   "metadata": {},
   "source": [
    "#### Antes de remover a variável \"grade\" vamos checar se realmente as duas variáveis estão relacionadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "cee2959e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', 'A', 'B', 'C', 'D', 'E', 'F', 'G'], dtype='<U69')"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando os valores unicos da variavel grade\n",
    "# Veja que existe valor ausente\n",
    "np.unique(dados_str[:,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "09618a79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A', 'B', 'C', 'D', 'E', 'F', 'G'], dtype='<U69')"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vamos desconsiderar o valor unico com slicing que vc conhece\n",
    "np.unique(dados_str[:,3])[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c2beaaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop para ajustar a variavel sub_grade\n",
    "# Vamos verificar se o valor está vazio e ao mesmo tempo (usando & significa E)\n",
    "\n",
    "# SE a variavel \"subgrade\" for vazio e \"grade\" = i (se as duas condições forem True ao mesmo tempo)\n",
    "#   Vamos substituir o valor vazio por i + 5 \n",
    "# SENÃO \n",
    "#   Manteremos o valor da \"sub grade\"\n",
    "\n",
    "# Lembrando que não é uma soma pois o i e uma letra\n",
    "# Isso vai ser uma concatenação do i com o numero 5, exemplo H1\n",
    "\n",
    "for i in np.unique(dados_str[:,3])[1:]:\n",
    "    dados_str[:,4] = np.where((dados_str[:,4] == '') & (dados_str[:,3] == i), i + '5', dados_str[:,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f6a71c10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['', 'A1', 'A2', 'A3', 'A4', 'A5', 'B1', 'B2', 'B3', 'B4', 'B5', 'C1', 'C2', 'C3', 'C4', 'C5', 'D1', 'D2', 'D3', 'D4', 'D5', 'E1', 'E2', 'E3', 'E4', 'E5', 'F1', 'F2', 'F3', 'F4', 'F5', 'G1',\n",
       "        'G2', 'G3', 'G4', 'G5'], dtype='<U69'),\n",
       " array([  9, 285, 278, 239, 323, 592, 509, 517, 530, 553, 633, 629, 567, 586, 564, 577, 391, 267, 250, 255, 288, 235, 162, 171, 139, 160,  94,  52,  34,  43,  24,  19,  10,   3,   7,   5]))"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vamos agora retornar cada categoria unica de \"sub grade\"\n",
    "# Com a quantidade de vezes que cada categoria aparece no dataset\n",
    "np.unique(dados_str[:,4], return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2a76cec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perceba que ainda temos valor AUSENTE ('') sobrando, pois tratamos os valores com duas condições\n",
    "\n",
    "# AGORA VAMOS TRATAR VALORES AUSENTES NAS DUAS COLUNAS \n",
    "\n",
    "# Agora vamos criar uma nova categoria para os valores que estão vazios em grade e sub grade\n",
    "# Se o valor for == vazio vamos colocar H1 se não manteremos o valor original do sub grade\n",
    "dados_str[:,4] = np.where(dados_str[:,4] == '', 'H1', dados_str[:,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "aa94ce90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['A1', 'A2', 'A3', 'A4', 'A5', 'B1', 'B2', 'B3', 'B4', 'B5', 'C1', 'C2', 'C3', 'C4', 'C5', 'D1', 'D2', 'D3', 'D4', 'D5', 'E1', 'E2', 'E3', 'E4', 'E5', 'F1', 'F2', 'F3', 'F4', 'F5', 'G1', 'G2',\n",
       "        'G3', 'G4', 'G5', 'H1'], dtype='<U69'),\n",
       " array([285, 278, 239, 323, 592, 509, 517, 530, 553, 633, 629, 567, 586, 564, 577, 391, 267, 250, 255, 288, 235, 162, 171, 139, 160,  94,  52,  34,  43,  24,  19,  10,   3,   7,   5,   9]))"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extrai os valores únicos da variável\n",
    "np.unique(dados_str[:,4], return_counts = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fe626f",
   "metadata": {},
   "source": [
    "#### Agora vamos <B>remover a variável GRADE</B>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "051db458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo a variável \"grade\" com np.delete\n",
    "# Remoção em nível de linha\n",
    "# Cuidado com esta função pois estamos passando um indice\n",
    "# Se executarmos esta função várias vezes, iremos remover mais colunas e não é o que queremos\n",
    "dados_str = np.delete(dados_str, 3, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "dc6649e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['C3', 'A5', 'B5', ..., 'A5', 'D2', 'A4'], dtype='<U69')"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veja que agora a variável de índice 3 é a sub grade\n",
    "dados_str[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "bd95b1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora vamos remover da nossa lista de cabeçalhos tbm a coluna grade\n",
    "nomes_colunas_str = np.delete(nomes_colunas_str, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "2a35a1e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sub_grade'"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mais uma vez veja que o indice 3 agora corresponde a outra coluna\n",
    "# Cuidado com isso!\n",
    "nomes_colunas_str[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892d3f70",
   "metadata": {},
   "source": [
    "#### Agora vamos converter a variável para sua versão numérica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "8eb2648f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A1', 'A2', 'A3', 'A4', 'A5', 'B1', 'B2', 'B3', 'B4', 'B5', 'C1', 'C2', 'C3', 'C4', 'C5', 'D1', 'D2', 'D3', 'D4', 'D5', 'E1', 'E2', 'E3', 'E4', 'E5', 'F1', 'F2', 'F3', 'F4', 'F5', 'G1', 'G2',\n",
       "       'G3', 'G4', 'G5', 'H1'], dtype='<U69')"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando os valores unicos da nova variavel do indice 3\n",
    "np.unique(dados_str[:,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "df94098c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A1'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vamos criar um dicionário em python\n",
    "# Conjunto de pares de chave e valor\n",
    "# Na chave vamos colocar as categorias\n",
    "# Veja que estamos criando a lista de chaves no objeto chaves\n",
    "chaves = list(np.unique(dados_str[:,3]))     \n",
    "chaves[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f946919e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36,)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(dados_str[:,3]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "11f3f0fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criando a lista de valores que serão os números\n",
    "# A primeira categoria vai receber o número 1 a segunda categoria o número 2, etc\n",
    "# Vamos criar uma lista com a função \"arange\"\n",
    "# Para cada valor unico da coluna \"sub grade\" vamos fazer +1\n",
    "# Para ficar a contagem 1 2 3 4 5 certinha que vamos utilizar \n",
    "valores = list(range(1, np.unique(dados_str[:,3]).shape[0] + 1)) \n",
    "valores[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "9e6c0b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36]\n"
     ]
    }
   ],
   "source": [
    "print(valores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "280b7b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos criar o dicionário com dict \n",
    "# e concatenar as chaves e valores do dicionário novo com zip\n",
    "\n",
    "dicionario_sub_grade = dict(zip(chaves, valores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "7fd07022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A1': 1,\n",
       " 'A2': 2,\n",
       " 'A3': 3,\n",
       " 'A4': 4,\n",
       " 'A5': 5,\n",
       " 'B1': 6,\n",
       " 'B2': 7,\n",
       " 'B3': 8,\n",
       " 'B4': 9,\n",
       " 'B5': 10,\n",
       " 'C1': 11,\n",
       " 'C2': 12,\n",
       " 'C3': 13,\n",
       " 'C4': 14,\n",
       " 'C5': 15,\n",
       " 'D1': 16,\n",
       " 'D2': 17,\n",
       " 'D3': 18,\n",
       " 'D4': 19,\n",
       " 'D5': 20,\n",
       " 'E1': 21,\n",
       " 'E2': 22,\n",
       " 'E3': 23,\n",
       " 'E4': 24,\n",
       " 'E5': 25,\n",
       " 'F1': 26,\n",
       " 'F2': 27,\n",
       " 'F3': 28,\n",
       " 'F4': 29,\n",
       " 'F5': 30,\n",
       " 'G1': 31,\n",
       " 'G2': 32,\n",
       " 'G3': 33,\n",
       " 'G4': 34,\n",
       " 'G5': 35,\n",
       " 'H1': 36}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veja que criamos um número único correspondente para cada categoria única\n",
    "\n",
    "dicionario_sub_grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "78f2a91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora vamos criar um loop para substituir as categorias que estão em texto\n",
    "# Ou seja aplicaremos o Label Encoding na coluna \"sub grade\"\n",
    "\n",
    "# Para cada valor unico da coluna \"sub grade\"\n",
    "        # Onde o valor for igual a i iremos substituilo por seu numero correspondente do dicionario\n",
    "        # Se nao manteremos o numero\n",
    "for i in np.unique(dados_str[:,3]):\n",
    "        dados_str[:,3] = np.where(dados_str[:,3] == i, dicionario_sub_grade[i], dados_str[:,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "be1b2aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '2', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '3', '30', '31', '32', '33', '34', '35', '36', '4', '5', '6',\n",
       "       '7', '8', '9'], dtype='<U69')"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extrai os valores únicos da variável\n",
    "np.unique(dados_str[:,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446e2075",
   "metadata": {},
   "source": [
    "### Transformando a variável <b>verification_status</b> com Binarização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "d08b7ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_date', 'loan_status', 'term_months', 'sub_grade', 'verification_status', 'url', 'addr_state'], dtype='<U19')"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vamos ver as colunas novamente\n",
    "nomes_colunas_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "e3e64c2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', 'Not Verified', 'Source Verified', 'Verified'], dtype='<U69')"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando valores únicos da variavel\n",
    "# Veja que possui valor vazio também\n",
    "# Vamos considerar o vazio como \"não verificado\" pois é o que faz mais sentido\n",
    "\n",
    "np.unique(dados_str[:,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "47a80f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos então aplicar a binarização\n",
    "# SE o valor do dado for igual a vazio '' OU (| = OU LOGICO) se for igual a \"Not Verified\" \n",
    "    # vamos substituir ambos vazio e Not Verified por 0\n",
    "# SE nao for nem vazio nem Not Verified vamos colocar o 1\n",
    "\n",
    "dados_str[:,4] = np.where((dados_str[:,4] == '') | (dados_str[:,4] == 'Not Verified'), 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "d84ac256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '1'], dtype='<U69')"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando navemente os valores únicos da variável / coluna\n",
    "np.unique(dados_str[:,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9168f425",
   "metadata": {},
   "source": [
    "### Transformando a variavel <b>url</b> com extração de ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "5ec96372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['https://www.lendingclub.com/browse/loanDetail.action?loan_id=48010226', 'https://www.lendingclub.com/browse/loanDetail.action?loan_id=57693261',\n",
       "       'https://www.lendingclub.com/browse/loanDetail.action?loan_id=59432726', ..., 'https://www.lendingclub.com/browse/loanDetail.action?loan_id=50415990',\n",
       "       'https://www.lendingclub.com/browse/loanDetail.action?loan_id=46154151', 'https://www.lendingclub.com/browse/loanDetail.action?loan_id=66055249'], dtype='<U69')"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vamos ver a coluna URL que indica cada empréstimo\n",
    "# Perceba que existe um padrão no texto padronizadas\n",
    "# No final de cada url temos um ID\n",
    "# Com este padrao detectado podemos entao pegar este ID no final de cada URL\n",
    "\n",
    "dados_str[:,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "29c6f3a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "chararray(['48010226', '57693261', '59432726', ..., '50415990', '46154151', '66055249'], dtype='<U69')"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vamos pegar o ID simplesmente removendo tudo que não seja ele\n",
    "# Usamos o strip na coluna url e removemos todo o texto menos o ID\n",
    "# Como a parte inicial da URL é a mesma, vamos remove-la\n",
    "\n",
    "np.chararray.strip(dados_str[:,5], \"https://www.lendingclub.com/browse/loanDetail.action?loan_id=\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "bc7e4fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos atualizar esta coluna apenas com os ID's mantivemos\n",
    "\n",
    "dados_str[:,5] = np.chararray.strip(dados_str[:,5], \n",
    "                                      \"https://www.lendingclub.com/browse/loanDetail.action?loan_id=\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "6c8fbad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([48010226, 57693261, 59432726, ..., 50415990, 46154151, 66055249], dtype=int32)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vamos converter para o tipo int\n",
    "# Perceba que agora não é mais uma string\n",
    "\n",
    "dados_str[:,5].astype(dtype = np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "62478996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([48010226, 57693261, 59432726, ..., 50415990, 46154151, 66055249], dtype=int32)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se analisarmos os dados, já temos uma coluna de ID\n",
    "# Porém está no conjunto de dados numéricos que separamos\n",
    "# Vamos verificar e converter para int 32 e comparar\n",
    "\n",
    "dados_num[:,0].astype(dtype = np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "78bcd8be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Além disto, vamos verificar se os valores das duas colunas sao iguais\n",
    "# Muito provavelmente é para ser igual\n",
    "# Visto que a URL é feita para cada ID\n",
    "# Vamos comparar as duas colunas de datasets diferentes \n",
    "\n",
    "np.array_equal(dados_num[:,0].astype(dtype = np.int32), dados_str[:,5].astype(dtype = np.int32))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2a9ff8",
   "metadata": {},
   "source": [
    "#### Já que temos informação duplicada, então vamos remover uma das colunas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "dc920f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos remover a coluna URL \n",
    "dados_str = np.delete(dados_str, 5, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "4377219e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Claro, vamos remover tbm a url da nossa lista de cabecalhos\n",
    "nomes_colunas_str = np.delete(nomes_colunas_str, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "5790ba8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CA', 'NY', 'PA', ..., 'CA', 'OH', 'IL'], dtype='<U69')"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veja a nova coluna de indice 5\n",
    "dados_str[:,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "80483bd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_date', 'loan_status', 'term_months', 'sub_grade', 'verification_status', 'addr_state'], dtype='<U19')"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# E veja a nova lista de colunas do tipo texto, a coluna url sumiu\n",
    "nomes_colunas_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "e1c67e08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([48010226., 57693261., 59432726., ..., 50415990., 46154151., 66055249.])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veja a coluna que mantivemos\n",
    "dados_num[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "d6519449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'loan_amnt', 'funded_amnt', 'int_rate', 'installment', 'total_pymnt'], dtype='<U19')"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A Coluna id esta no conjunto de colunas numericas\n",
    "nomes_colunas_num"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eaa673c",
   "metadata": {},
   "source": [
    "### Trabalhando com a variável <b>address</b> com Categorizacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "cd701aa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['issue_date', 'loan_status', 'term_months', 'sub_grade', 'verification_status', 'addr_state'], dtype='<U19')"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nomes_colunas_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "8ac68be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos padronizar o nome da coluna\n",
    "nomes_colunas_str[5] = \"state_address\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2cafc5",
   "metadata": {},
   "source": [
    "https://numpy.org/doc/stable/reference/generated/numpy.argsort.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "8e1605ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 0])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exemplo np.argsort\n",
    "x = np.array([3, 1, 2])\n",
    "np.argsort(x)\n",
    "#array([1, 2, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "f28d691e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos pegar cada valor unico e a quantidade de vezes que ele aparece\n",
    "# Como esta operacao retorna dois valores vamos coloca-los em duas variaveis diferentes\n",
    "nomes_estados, total_estados = np.unique(dados_str[:,5], return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "ca403515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos usar o argsort para ordenar os estados em ordem decrescente\n",
    "# Com base na frequencia que tivemos no comando acima\n",
    "# O sinal de - é para indicar a ordem decrescente\n",
    "estados_ordenados = np.argsort(-total_estados)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "2c2a9997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5, 33, 42, 10,  0, 13, 30, 11, 37, 34, 21, 26, 44, 19,  4, 46, 18,  6, 23, 22, 14, 47,  7, 41, 32,  2, 17, 36, 39, 16, 15, 35, 43,  3, 24, 29, 31, 48, 12, 38, 25,  9,  8, 49,  1, 28, 40, 45,\n",
       "       27, 20])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estados_ordenados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "82bec928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['', 'AK', 'AL', 'AR', 'AZ', 'CA', 'CO', 'CT', 'DC', 'DE', 'FL', 'GA', 'HI', 'IL', 'IN', 'KS', 'KY', 'LA', 'MA', 'MD', 'ME', 'MI', 'MN', 'MO', 'MS', 'MT', 'NC', 'ND', 'NE', 'NH', 'NJ', 'NM',\n",
       "        'NV', 'NY', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC', 'SD', 'TN', 'TX', 'UT', 'VA', 'VT', 'WA', 'WI', 'WV', 'WY'], dtype='<U69'),\n",
       " array([ 500,   26,  119,   74,  220, 1336,  201,  143,   27,   27,  690,  321,   44,  389,  152,   84,   84,  116,  210,  222,   10,  267,  156,  160,   61,   28,  261,   16,   25,   58,  341,   57,\n",
       "         130,  777,  312,   83,  108,  320,   40,  107,   24,  143,  758,   74,  242,   17,  216,  148,   49,   27]))"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(dados_str[:,5], return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "0d70db9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['CA', 'NY', 'TX', 'FL', '', 'IL', 'NJ', 'GA', 'PA', 'OH', 'MI', 'NC', 'VA', 'MD', 'AZ', 'WA', 'MA', 'CO', 'MO', 'MN', 'IN', 'WI', 'CT', 'TN', 'NV', 'AL', 'LA', 'OR', 'SC', 'KY', 'KS', 'OK',\n",
       "        'UT', 'AR', 'MS', 'NH', 'NM', 'WV', 'HI', 'RI', 'MT', 'DE', 'DC', 'WY', 'AK', 'NE', 'SD', 'VT', 'ND', 'ME'], dtype='<U69'),\n",
       " array([1336,  777,  758,  690,  500,  389,  341,  321,  320,  312,  267,  261,  242,  222,  220,  216,  210,  201,  160,  156,  152,  148,  143,  143,  130,  119,  116,  108,  107,   84,   84,   83,\n",
       "          74,   74,   61,   58,   57,   49,   44,   40,   28,   27,   27,   27,   26,   25,   24,   17,   16,   10]))"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perceba que temos um array com os estados\n",
    "# E outro array com o número de vezes que cada estado aparece na ordem decrescente\n",
    "nomes_estados[estados_ordenados], total_estados[estados_ordenados]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "03d6681b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos substituir os valores ausentes por 0\n",
    "dados_str[:,5] = np.where(dados_str[:,5] == '', 0, dados_str[:,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "5ea10f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos criar uma lista de estados pertecentes a cada região\n",
    "estados_oeste = np.array(['WA', 'OR','CA','NV','ID','MT', 'WY','UT','CO', 'AZ','NM','HI','AK'])\n",
    "estados_sul = np.array(['TX','OK','AR','LA','MS','AL','TN','KY','FL','GA','SC','NC','VA','WV','MD','DE','DC'])\n",
    "estados_centro_oeste = np.array(['ND','SD','NE','KS','MN','IA','MO','WI','IL','IN','MI','OH'])\n",
    "estados_leste = np.array(['PA','NY','NJ','CT','MA','VT','NH','ME','RI'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "491c6be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tomamos a decisão de substituir cada estado pelo ID da Região \n",
    "# Com base nas listas que criamos de regiões vamos atribuir um id para cada região e então fazer isso\n",
    "# Isso é a decisão que tomamos e pode variar de caso para caso\n",
    "dados_str[:,5] = np.where(np.isin(dados_str[:,5], estados_oeste), 1, dados_str[:,5])\n",
    "dados_str[:,5] = np.where(np.isin(dados_str[:,5], estados_sul), 2, dados_str[:,5])\n",
    "dados_str[:,5] = np.where(np.isin(dados_str[:,5], estados_centro_oeste), 3, dados_str[:,5])\n",
    "dados_str[:,5] = np.where(np.isin(dados_str[:,5], estados_leste), 4, dados_str[:,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "3d464c8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '1', '2', '3', '4'], dtype='<U69')"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A coluna foi alterada contendo os respectivos id's\n",
    "# E então o valor 0 corresponde a valor nulo\n",
    "# E os outros ID's para suas respectivas regiões correspondentes\n",
    "# Chamamos isso de CATEGORIZAÇÃO\n",
    "# Perceba que a informação que queremos que ela representa nao foi alterada\n",
    "# Importante preservar a informação mesmo que aplique transformação nos dados\n",
    "# A informação nao pode ser distorcida\n",
    "\n",
    "np.unique(dados_str[:,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259d4853",
   "metadata": {},
   "source": [
    "#### Com isso nós tratamos todas as colunas do tipo texto e nao temos mais dados do tipo string, todos os dados foram passados para o tipo número, porém não perdemos a informação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "1a4508b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['5', '1', '36', '13', '1', '1'],\n",
       "       ['0', '1', '36', '5', '1', '4'],\n",
       "       ['9', '1', '36', '10', '1', '4'],\n",
       "       ...,\n",
       "       ['6', '1', '36', '5', '1', '1'],\n",
       "       ['4', '1', '36', '17', '1', '3'],\n",
       "       ['12', '1', '36', '4', '0', '3']], dtype='<U69')"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945d54c6",
   "metadata": {},
   "source": [
    "### Manipulação de Variáveis Numéricas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2ffc98",
   "metadata": {},
   "source": [
    "#### Fazer a correção e até muitas vezes trabalhar com variáveis do tipo texto ou categóricas é muito mais trabalhoso, pois precisamos encontrar padrões, fazer muitas alterações, converter para valores numéricos para modelos de Machine Learning, criar novas categorias dependendo do caso.\n",
    "\n",
    "#### Porém trabalhar com variáveis numéricas costuma ser mais fácil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "07bfbbd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[48010226.  ,    35000.  ,    35000.  ,       13.33,     1184.86,     9452.96],\n",
       "       [57693261.  ,    30000.  ,    30000.  , 68616522.  ,      938.57,     4679.7 ],\n",
       "       [59432726.  ,    15000.  ,    15000.  , 68616522.  ,      494.86,     1969.83],\n",
       "       ...,\n",
       "       [50415990.  ,    10000.  ,    10000.  , 68616522.  , 68616522.  ,     2185.64],\n",
       "       [46154151.  , 68616522.  ,    10000.  ,       16.55,      354.3 ,     3199.4 ],\n",
       "       [66055249.  ,    10000.  ,    10000.  , 68616522.  ,      309.97,      301.9 ]])"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analisando as colunas numéricas \n",
    "dados_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "ec8f1fa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'loan_amnt', 'funded_amnt', 'int_rate', 'installment', 'total_pymnt'], dtype='<U19')"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cabeçalhos das colunas numéricas\n",
    "nomes_colunas_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "8d1854c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lembre que já substituímos os valores ausentes\n",
    "# Por um número identificador que é o MAX + 3 \n",
    "\n",
    "np.isnan(dados_num).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "83029f90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68616522.0"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Este é o número que criamos para identificar os valores \"nan\"\n",
    "\n",
    "valores_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "3c3bf54a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False, False, False])"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vamos verificar se as colunas foram preenchidas \n",
    "# Podemos checar se uma coluna foi preenchida com o \"valores_nan\"\n",
    "\n",
    "np.isin(dados_num[:,0], valores_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "997a9868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vamos ver quantos valores foram preenchidos da coluna ID o indice 0 \n",
    "# Podemos checar se uma coluna foi preenchida com o valor coringa\n",
    "# Veja que realmente nao há valores nulos na coluna id\n",
    "\n",
    "np.isin(dados_num[:,0], valores_nan).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825943da",
   "metadata": {},
   "source": [
    "### Uma forma de preencher valores ausentes em dados numéricos é utilizarmos a estatística ou então desconsiderar aquela linha que tem valor vazio, vamos trabalhar para este exemplo com a primeira opção que é a mais trabalhosa e que agrega mais valor ao nosso portfólio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "96eeac53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos criar um array de estatistica contendo o valor mínimo, valor máximo e a média \n",
    "#       (todos ignorando valores \"nan\")\n",
    "# Vamos usar estas estatísticas para substituir os valores ausentes\n",
    "# Vamos usar o \"nanmin\" para ter valores mínimos em nível de coluna\n",
    "# Vamos usar o \"media_sem_nan\" que criamos no início do projeto antes de inserir o valores_nan que criamos\n",
    "\n",
    "dados_estatisticos = np.array([np.nanmin(dados1, axis = 0), media_sem_nan, np.nanmax(dados1, axis = 0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "f92c07ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  373332.               nan     1000.               nan     1000.               nan        6.           31.42             nan           nan           nan           nan           nan        0.    ]\n",
      " [54015809.1922           nan    15273.4632           nan    15311.0421           nan       16.6173      440.9222           nan           nan           nan           nan           nan     3143.8509]\n",
      " [68616519.               nan    35000.               nan    35000.               nan       28.99       1372.97             nan           nan           nan           nan           nan    41913.62  ]]\n"
     ]
    }
   ],
   "source": [
    "print(dados_estatisticos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "199863ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  373332.    ,     1000.    ,     1000.    ,        6.    ,       31.42  ,        0.    ],\n",
       "       [54015809.1922,    15273.4632,    15311.0421,       16.6173,      440.9222,     3143.8509],\n",
       "       [68616519.    ,    35000.    ,    35000.    ,       28.99  ,     1372.97  ,    41913.62  ]])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"cols_num\" são os índices das colunas numéricas que criamos no início do projeto\n",
    "\n",
    "# Vamos ver os valores estatísticos para cada coluna numérica que geramos\n",
    "# Vamos usar estes valores para substituir os null's de suas respectivas colunas\n",
    "dados_estatisticos[:, cols_num]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876ca63d",
   "metadata": {},
   "source": [
    "### Trabalhando com a variável <b>funded_amnt</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "5de3cdd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([35000., 30000., 15000., ..., 10000., 10000., 10000.])"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vamos verificar os dados da coluna\n",
    "dados_num[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "809a7674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000.0"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vamos ver o valor estatistico que iremos substituir nesta coluna\n",
    "dados_estatisticos[0, cols_num[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "c160589c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substituindo os valores ausentes da coluna\n",
    "# Onde o valor da coluna for igual valores_nan (que criamos como identificador)\n",
    "# Vamos substituí-lo pelos dados_estatisticos de sua coluna correspondente\n",
    "# SE o valor NÃO for == valores_nan \n",
    "#       vamos mante-lo\n",
    "dados_num[:,2] = np.where(dados_num[:,2] == valores_nan, dados_estatisticos[0, cols_num[2]], dados_num[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "abcbcbe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([35000., 30000., 15000., ..., 10000., 10000., 10000.])"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Então veja que os valores \"nan\" que codificamos no inicio do projeto\n",
    "# Foram substituidos por uma medida estatistica\n",
    "# Essa é uma das saídas para preencher valores ausentes de variáveis/colunas numéricas\n",
    "\n",
    "dados_num[:,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda898ce",
   "metadata": {},
   "source": [
    "### Trabalhando com as variáveis <b>loan_amnt, int_rate, installment e total_pymnt</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "fdb95d7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'loan_amnt', 'funded_amnt', 'int_rate', 'installment', 'total_pymnt'], dtype='<U19')"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loop fazendo o mesmo para as variáveis que faltam\n",
    "\n",
    "nomes_colunas_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "b2843df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop para substituir o valor ausente (valor_coringa) pelos valores do array de estatísticas\n",
    "# Para cada indice [1,3,4,5] as colunas que faltam corrigir\n",
    "# SE os valores da coluna for == valores_nan,\n",
    "    # Substitua pelo valor estatistico de sua respectiva coluna correspondente\n",
    "# SENAO mantenha o valor original\n",
    "for i in [1,3,4,5]:\n",
    "    dados_num[:,i] = np.where(dados_num[:,i] == valores_nan, \n",
    "                                dados_estatisticos[2, cols_num[i]], \n",
    "                                dados_num[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "938d03b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[48010226.  ,    35000.  ,    35000.  ,       13.33,     1184.86,     9452.96],\n",
       "       [57693261.  ,    30000.  ,    30000.  ,       28.99,      938.57,     4679.7 ],\n",
       "       [59432726.  ,    15000.  ,    15000.  ,       28.99,      494.86,     1969.83],\n",
       "       ...,\n",
       "       [50415990.  ,    10000.  ,    10000.  ,       28.99,     1372.97,     2185.64],\n",
       "       [46154151.  ,    35000.  ,    10000.  ,       16.55,      354.3 ,     3199.4 ],\n",
       "       [66055249.  ,    10000.  ,    10000.  ,       28.99,      309.97,      301.9 ]])"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_num"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4872a5f9",
   "metadata": {},
   "source": [
    "#### Agora o projeto estÁ na parte final, vamos unir novamente os datasets de texto e números e vamos gravar este outro dataset sem substituir o dataset sujo original.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "31c67bb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 6)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dados daS variáveis texto que foram transformadas\n",
    "\n",
    "dados_str.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "7dd06428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 6)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dados das variaveis numericas que foram transformados\n",
    "# número de linhas são o mesmo, tem que ser assim se não estaria errado\n",
    "# Pois estamos trabalhando com apenas 1 dataset só que de forma separada\n",
    "# o número de colunas não precisa ser o mesmo mas o de linhas sim\n",
    "\n",
    "dados_num.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9b10fa",
   "metadata": {},
   "source": [
    "<b>HSTACK</b>\n",
    "\n",
    "https://datascienceparichay.com/wp-content/uploads/2021/08/numpy-hstack-to-horizontally-stack-arrays-1.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "972af970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 12)"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vamos concatenar os dois datasets\n",
    "# Concatena os arrays\n",
    "\n",
    "df_final = np.hstack((dados_num, dados_str))\n",
    "df_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "b95ca03b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['48010226.0', '35000.0', '35000.0', ..., '13', '1', '1'],\n",
       "       ['57693261.0', '30000.0', '30000.0', ..., '5', '1', '4'],\n",
       "       ['59432726.0', '15000.0', '15000.0', ..., '10', '1', '4'],\n",
       "       ...,\n",
       "       ['50415990.0', '10000.0', '10000.0', ..., '5', '1', '1'],\n",
       "       ['46154151.0', '35000.0', '10000.0', ..., '17', '1', '3'],\n",
       "       ['66055249.0', '10000.0', '10000.0', ..., '4', '0', '3']], dtype='<U69')"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "8c273472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12,)"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Agora vamos concatenar os cabeçalhos que criamos\n",
    "# Concatena os arrays de nomes de colunas\n",
    "cabecalho_completo = np.concatenate((nomes_colunas_num, nomes_colunas_str))\n",
    "cabecalho_completo.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb28cf2",
   "metadata": {},
   "source": [
    "### Gravando o Dataset Final Limpo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc2ceff",
   "metadata": {},
   "source": [
    "<b>VSTACK</b>\n",
    "\n",
    "https://i1.wp.com/www.sharpsightlabs.com/wp-content/uploads/2019/07/np-vstack_combine-two-2D-arrays-1.png?w=542&ssl=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "b25b668c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos juntar as colunas com seus cabecalhos\n",
    "# Concatena o array de nomes de colunas com o array de dados\n",
    "df_final = np.vstack((cabecalho_completo, df_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "a4952a20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['id', 'loan_amnt', 'funded_amnt', ..., 'sub_grade', 'verification_status', 'state_address'],\n",
       "       ['48010226.0', '35000.0', '35000.0', ..., '13', '1', '1'],\n",
       "       ['57693261.0', '30000.0', '30000.0', ..., '5', '1', '4'],\n",
       "       ...,\n",
       "       ['50415990.0', '10000.0', '10000.0', ..., '5', '1', '1'],\n",
       "       ['46154151.0', '35000.0', '10000.0', ..., '17', '1', '3'],\n",
       "       ['66055249.0', '10000.0', '10000.0', ..., '4', '0', '3']], dtype='<U69')"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "b7aa761d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando em disco o novo dataset limpo\n",
    "\n",
    "np.savetxt(\"dataset_limpo_v03h40.csv\", \n",
    "           df_final, \n",
    "           fmt = '%s',\n",
    "           delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2765925",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
